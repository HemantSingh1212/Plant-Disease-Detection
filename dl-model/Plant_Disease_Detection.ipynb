{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b69d61",
   "metadata": {},
   "source": [
    "# Github repo url\n",
    "\n",
    "[https://github.com/SkyDocs/Plant-Disease-Detection](https://github.com/SkyDocs/Plant-Disease-Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb7e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822ca8d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  dataset.zip\n",
      "replace dataset/train/Cherry___Powdery_mildew/00b7df55-c789-43d6-a02e-a579ac9d07e6___FREC_Pwd.M 4748.JPG? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08086659",
   "metadata": {},
   "source": [
    "dataset classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be4b291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainData():\n",
    "    def __inti__(self):\n",
    "        self.lables, self.image_list = self.load_data()\n",
    "        \n",
    "    def load_data(self):\n",
    "        resize = transforms.Compose([transforms.Resize(256, 256)])\n",
    "        train_dir = os.listdir(os.path.join(\"dataset\", \"train\"))\n",
    "        \n",
    "        ref = {}\n",
    "        lables = {}\n",
    "        image_list = {}\n",
    "        global_count = 0\n",
    "         \n",
    "        for i,dir in enumerate(train_dir):\n",
    "            ref[dir] = i\n",
    "            images = os.listdir(os.path.join(\"dataset\", \"train\", dir))\n",
    "            count = 0\n",
    "            for img in images:\n",
    "                if count < 500:\n",
    "                    lables[count] = i\n",
    "                    img = os.path.join(\"dataset\", \"train\", dir, img)\n",
    "                    image = Image.open(img)\n",
    "                    image = ToTensor()(image)\n",
    "                    image_list[count] = resize(image)\n",
    "                    count += 1\n",
    "                    global_count += 1\n",
    "                    print(i)\n",
    "                else:\n",
    "                    pirnt(\"Taken 500 images for training\")\n",
    "                    break\n",
    "        \n",
    "        print(reference)\n",
    "        return lables,image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827cf7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = trainData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d0aa4",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b06d7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(neuralNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5)\n",
    "        self.conv4 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=48*12*12,out_features=240)\n",
    "        self.fc2 = nn.Linear(in_features=240,out_features=120)\n",
    "        self.out = nn.Linear(in_features=120,out_features=17)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        x = x.reshape(-1, 48*12*12)\n",
    "        x = x.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d91c4f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f34ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
